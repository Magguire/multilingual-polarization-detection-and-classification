{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-136308904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeightedRandomSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mUninitializedParameter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch.nn import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mattention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from .activation import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mCELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeviceLikeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackwardHook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_python_dispatch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m from torch._C import (\n\u001b[1;32m     15\u001b[0m     \u001b[0m_get_dispatch_stack_at\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchgen/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Represent a source location; used for better error reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLocation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/dataclasses.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         return _process_class(cls, init, repr, eq, order, unsafe_hash,\n\u001b[0m\u001b[1;32m   1266\u001b[0m                               \u001b[0mfrozen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m                               weakref_slot)\n",
      "\u001b[0;32m/usr/lib/python3.12/dataclasses.py\u001b[0m in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mflds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfield_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0m_set_new_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_repr_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/dataclasses.py\u001b[0m in \u001b[0;36m_repr_fn\u001b[0;34m(fields, globals)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_repr_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m     fn = _create_fn('__repr__',\n\u001b[0m\u001b[1;32m    629\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'self'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                     ['return self.__class__.__qualname__ + f\"(' +\n",
      "\u001b[0;32m/usr/lib/python3.12/dataclasses.py\u001b[0m in \u001b[0;36m_create_fn\u001b[0;34m(name, args, body, globals, locals, return_type)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"def __create_fn__({local_vars}):\\n{txt}\\n return {name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__create_fn__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchgen/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SemEval Task 9 - Subtask 2: SIMPLIFIED Multi-Label Classification\n",
    "Target: F1-Macro >= 0.65+ for both languages\n",
    "\n",
    "STRATEGY - BACK TO BASICS:\n",
    "âœ“ Standard BCE loss (proven to work for multi-label)\n",
    "âœ“ Positive class weighting per label\n",
    "âœ“ More epochs with early stopping\n",
    "âœ“ Better threshold search\n",
    "âœ“ No complex sampling - keep it simple\n",
    "\"\"\"\n",
    "\n",
    "import os, pandas as pd, numpy as np, torch, torch.nn as nn\n",
    "import re, random, gc, warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                         get_linear_schedule_with_warmup, set_seed)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "set_seed(42)\n",
    "\n",
    "class Config:\n",
    "    BASE_PATH = '/content/drive/MyDrive/NLP'\n",
    "    TRAIN_ENG = f'{BASE_PATH}/subtask2/train/eng.csv'\n",
    "    TRAIN_SWA = f'{BASE_PATH}/subtask2/train/swa.csv'\n",
    "    DEV_ENG = f'{BASE_PATH}/subtask2/dev/eng.csv'\n",
    "    DEV_SWA = f'{BASE_PATH}/subtask2/dev/swa.csv'\n",
    "    OUTPUT_DIR = '/content/subtask2/models'\n",
    "    PREDICTIONS_DIR = '/content/subtask_2'\n",
    "    os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    MODEL_ENG = 'microsoft/deberta-v3-base'\n",
    "    MODEL_SWA = 'xlm-roberta-base'\n",
    "    MAX_LENGTH = 128\n",
    "\n",
    "    LABELS = ['political', 'racial/ethnic', 'religious', 'gender/sexual', 'other']\n",
    "    NUM_LABELS = 5\n",
    "\n",
    "    # Simple training params\n",
    "    BATCH_SIZE = 16\n",
    "    GRAD_ACCUM = 2\n",
    "    EPOCHS = 18\n",
    "    LR_ENG = 2e-5\n",
    "    LR_SWA = 2.5e-5\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    WARMUP_RATIO = 0.15\n",
    "    DROPOUT = 0.2\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "\n",
    "    VAL_SIZE = 0.18\n",
    "    USE_AUGMENTATION = False  # Disable augmentation - might add noise\n",
    "\n",
    "    USE_FP16 = True\n",
    "    SEED = 42\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device: {Config.DEVICE}\")\n",
    "\n",
    "class TextPreprocessor:\n",
    "    @staticmethod\n",
    "    def clean(text):\n",
    "        text = str(text).strip().lower()\n",
    "        text = re.sub(r'http\\S+|www\\.\\S+', ' [url] ', text)\n",
    "        text = re.sub(r'@\\w+', ' [user] ', text)\n",
    "        text = re.sub(r'#(\\w+)', r' \\1 ', text)\n",
    "        text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "        text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text if text else \"[empty]\"\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    \"\"\"BCE with per-label positive class weights\"\"\"\n",
    "    def __init__(self, pos_weights):\n",
    "        super().__init__()\n",
    "        self.pos_weights = torch.tensor(pos_weights, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        device = logits.device\n",
    "        pos_weights = self.pos_weights.to(device)\n",
    "\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=pos_weights, reduction='mean'\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "class MultiLabelModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=5, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.transformer = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\",\n",
    "            hidden_dropout_prob=dropout,\n",
    "            attention_probs_dropout_prob=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len, label_names):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label_names = label_names\n",
    "        self.prep = TextPreprocessor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.prep.clean(self.texts[idx])\n",
    "        label_vector = self.labels.iloc[idx][self.label_names].values.astype(np.float32)\n",
    "\n",
    "        enc = self.tokenizer(text, max_length=self.max_len, padding='max_length',\n",
    "                           truncation=True, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label_vector, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "def compute_pos_weights(df, label_names):\n",
    "    \"\"\"Compute positive class weights for BCE loss\"\"\"\n",
    "    pos_weights = []\n",
    "\n",
    "    print(\"  Computing pos_weights:\")\n",
    "    for label in label_names:\n",
    "        pos = df[label].sum()\n",
    "        neg = len(df) - pos\n",
    "\n",
    "        if pos == 0:\n",
    "            weight = 1.0\n",
    "        else:\n",
    "            # Weight = neg/pos, capped at 10\n",
    "            weight = min(10.0, neg / pos)\n",
    "\n",
    "        pos_weights.append(weight)\n",
    "        print(f\"    {label:20s}: pos={pos:5d}, neg={neg:5d}, weight={weight:.2f}\")\n",
    "\n",
    "    return pos_weights\n",
    "\n",
    "def load_data(path, label_names):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(TextPreprocessor.clean)\n",
    "    df = df[df['text'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "    print(f\"  Samples: {len(df)}\")\n",
    "    print(f\"  Label Distribution:\")\n",
    "\n",
    "    for label in label_names:\n",
    "        count = df[label].sum()\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"    {label:20s}: {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def find_optimal_thresholds(model, loader, device, label_names, use_fp16=False):\n",
    "    \"\"\"Find optimal threshold per label\"\"\"\n",
    "    print(\"  Finding thresholds...\")\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Probs\", leave=False):\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "\n",
    "            if use_fp16:\n",
    "                with autocast():\n",
    "                    out = model(ids, mask)\n",
    "                    probs = torch.sigmoid(out.logits)\n",
    "            else:\n",
    "                out = model(ids, mask)\n",
    "                probs = torch.sigmoid(out.logits)\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.numpy())\n",
    "\n",
    "    all_probs = np.vstack(all_probs).astype(np.float32)\n",
    "    all_labels = np.vstack(all_labels).astype(np.float32)\n",
    "\n",
    "    thresholds = []\n",
    "    for i, label in enumerate(label_names):\n",
    "        label_probs = all_probs[:, i]\n",
    "        label_true = all_labels[:, i]\n",
    "\n",
    "        pos_count = int(label_true.sum())\n",
    "\n",
    "        if pos_count < 3:\n",
    "            print(f\"    {label:20s}: too few ({pos_count}), using 0.5\")\n",
    "            thresholds.append(0.5)\n",
    "            continue\n",
    "\n",
    "        # Standard threshold search\n",
    "        threshs = np.linspace(0.1, 0.9, 81)\n",
    "        best_t, best_f1 = 0.5, 0.0\n",
    "\n",
    "        for t in threshs:\n",
    "            preds = (label_probs >= t).astype(np.float32)\n",
    "            f1 = f1_score(label_true, preds, average='binary', zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "\n",
    "        thresholds.append(best_t)\n",
    "        print(f\"    {label:20s}: t={best_t:.3f}, F1={best_f1:.4f}\")\n",
    "\n",
    "    return thresholds\n",
    "\n",
    "def train_epoch(model, loader, opt, sched, crit, device, grad_accum, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"  Train\", leave=False)):\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                out = model(ids, mask)\n",
    "                loss = crit(out.logits, labels) / grad_accum\n",
    "                probs = torch.sigmoid(out.logits)\n",
    "\n",
    "            batch_loss = loss.item() * grad_accum\n",
    "            all_preds.append((probs >= 0.5).long().cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % grad_accum == 0:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad()\n",
    "        else:\n",
    "            out = model(ids, mask)\n",
    "            loss = crit(out.logits, labels) / grad_accum\n",
    "\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(out.logits)\n",
    "\n",
    "            batch_loss = loss.item() * grad_accum\n",
    "            all_preds.append((probs >= 0.5).long().cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % grad_accum == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                opt.step()\n",
    "                sched.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    all_preds = np.vstack(all_preds).astype(np.float32)\n",
    "    all_labels = np.vstack(all_labels).astype(np.float32)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return total_loss / len(loader), f1_macro\n",
    "\n",
    "def evaluate(model, loader, crit, device, thresholds, label_names, use_fp16=False, show_report=True):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Eval\", leave=False):\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            if use_fp16:\n",
    "                with autocast():\n",
    "                    out = model(ids, mask)\n",
    "                    loss = crit(out.logits, labels)\n",
    "                    probs = torch.sigmoid(out.logits)\n",
    "            else:\n",
    "                out = model(ids, mask)\n",
    "                loss = crit(out.logits, labels)\n",
    "                probs = torch.sigmoid(out.logits)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.vstack(all_probs).astype(np.float32)\n",
    "    all_labels = np.vstack(all_labels).astype(np.float32)\n",
    "\n",
    "    all_preds = np.zeros_like(all_probs, dtype=np.float32)\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        all_preds[:, i] = (all_probs[:, i] >= thresh).astype(np.float32)\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    if show_report:\n",
    "        print(\"\\n  Per-label F1:\")\n",
    "        for i, label in enumerate(label_names):\n",
    "            f1 = f1_score(all_labels[:, i], all_preds[:, i], average='binary', zero_division=0)\n",
    "            print(f\"    {label:20s}: {f1:.4f}\")\n",
    "        print(f\"  Macro: {f1_macro:.4f}\")\n",
    "\n",
    "    return total_loss / len(loader), f1_macro\n",
    "\n",
    "def train_model(train_df, lang, model_name, lr, config):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {lang.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Compute pos_weights\n",
    "    pos_weights = compute_pos_weights(train_df, config.LABELS)\n",
    "\n",
    "    # Split\n",
    "    train_data, val_data = train_test_split(\n",
    "        train_df, test_size=config.VAL_SIZE, random_state=config.SEED\n",
    "    )\n",
    "\n",
    "    print(f\"\\n  Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_ds = MultiLabelDataset(train_data['text'].values, train_data, tokenizer,\n",
    "                                 config.MAX_LENGTH, config.LABELS)\n",
    "    val_ds = MultiLabelDataset(val_data['text'].values, val_data, tokenizer,\n",
    "                               config.MAX_LENGTH, config.LABELS)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, config.BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, config.BATCH_SIZE*2, shuffle=False,\n",
    "                           num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = MultiLabelModel(model_name, config.NUM_LABELS, config.DROPOUT).to(config.DEVICE)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr,\n",
    "                           weight_decay=config.WEIGHT_DECAY, eps=1e-8)\n",
    "\n",
    "    steps = len(train_loader) * config.EPOCHS // config.GRAD_ACCUM\n",
    "    warmup = int(steps * config.WARMUP_RATIO)\n",
    "    sched = get_linear_schedule_with_warmup(opt, warmup, steps)\n",
    "\n",
    "    crit = WeightedBCELoss(pos_weights)\n",
    "    scaler = GradScaler() if config.USE_FP16 else None\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_thresholds = [0.5] * config.NUM_LABELS\n",
    "    patience, p_cnt = 5, 0\n",
    "\n",
    "    for ep in range(config.EPOCHS):\n",
    "        print(f\"\\n[Epoch {ep+1}/{config.EPOCHS}]\")\n",
    "\n",
    "        tr_loss, tr_f1 = train_epoch(model, train_loader, opt, sched, crit,\n",
    "                                     config.DEVICE, config.GRAD_ACCUM, scaler)\n",
    "\n",
    "        val_loss, val_f1 = evaluate(model, val_loader, crit, config.DEVICE,\n",
    "                                    [0.5]*config.NUM_LABELS, config.LABELS,\n",
    "                                    config.USE_FP16, show_report=False)\n",
    "\n",
    "        print(f\"  Train: Loss={tr_loss:.4f}, F1={tr_f1:.4f}\")\n",
    "        print(f\"  Val:   Loss={val_loss:.4f}, F1={val_f1:.4f}\")\n",
    "\n",
    "        # Threshold search from epoch 5\n",
    "        if ep >= 5:\n",
    "            thresholds = find_optimal_thresholds(model, val_loader, config.DEVICE,\n",
    "                                                config.LABELS, config.USE_FP16)\n",
    "            _, val_f1 = evaluate(model, val_loader, crit, config.DEVICE, thresholds,\n",
    "                               config.LABELS, config.USE_FP16,\n",
    "                               show_report=(ep >= config.EPOCHS - 2))\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1, best_thresholds, p_cnt = val_f1, thresholds, 0\n",
    "                torch.save({\n",
    "                    'model': model.state_dict(),\n",
    "                    'thresholds': thresholds,\n",
    "                    'f1': float(val_f1)\n",
    "                }, f\"{config.OUTPUT_DIR}/best_{lang}.pt\", _use_new_zipfile_serialization=True)\n",
    "                print(f\"  âœ“ Saved (F1={best_f1:.4f})\")\n",
    "            else:\n",
    "                p_cnt += 1\n",
    "                print(f\"  No improvement ({p_cnt}/{patience})\")\n",
    "\n",
    "        if ep >= 8 and p_cnt >= patience:\n",
    "            print(\"  Early stopping\")\n",
    "            break\n",
    "\n",
    "    # Load best\n",
    "    ckpt = torch.load(f\"{config.OUTPUT_DIR}/best_{lang}.pt\",\n",
    "                     map_location=config.DEVICE, weights_only=False)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    best_f1 = ckpt['f1']\n",
    "    best_thresholds = ckpt['thresholds']\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FINAL: F1-Macro={best_f1:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return model, tokenizer, best_f1, best_thresholds\n",
    "\n",
    "def predict(model, tokenizer, test_file, out_file, thresholds, label_names, config):\n",
    "    print(f\"\\nPredicting: {test_file}\")\n",
    "\n",
    "    df = pd.read_csv(test_file)\n",
    "    df['text'] = df['text'].apply(TextPreprocessor.clean)\n",
    "\n",
    "    for label in label_names:\n",
    "        df[label] = 0\n",
    "\n",
    "    ds = MultiLabelDataset(df['text'].values, df, tokenizer, config.MAX_LENGTH, label_names)\n",
    "    loader = DataLoader(ds, config.BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Predict\", leave=False):\n",
    "            ids = batch['input_ids'].to(config.DEVICE)\n",
    "            mask = batch['attention_mask'].to(config.DEVICE)\n",
    "\n",
    "            if config.USE_FP16:\n",
    "                with autocast():\n",
    "                    out = model(ids, mask)\n",
    "                    probs = torch.sigmoid(out.logits)\n",
    "            else:\n",
    "                out = model(ids, mask)\n",
    "                probs = torch.sigmoid(out.logits)\n",
    "\n",
    "            all_preds.append(probs.cpu().numpy())\n",
    "\n",
    "    all_probs = np.vstack(all_preds)\n",
    "\n",
    "    predictions = np.zeros_like(all_probs, dtype=int)\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        predictions[:, i] = (all_probs[:, i] >= thresh).astype(int)\n",
    "\n",
    "    out_df = pd.DataFrame({'id': df['id']})\n",
    "    for i, label in enumerate(label_names):\n",
    "        out_df[label] = predictions[:, i]\n",
    "\n",
    "    out_df.to_csv(out_file, index=False)\n",
    "\n",
    "    print(f\"âœ“ Saved: {out_file}\")\n",
    "    for i, label in enumerate(label_names):\n",
    "        count = predictions[:, i].sum()\n",
    "        pct = count / len(predictions) * 100\n",
    "        print(f\"  {label:20s}: {count:5d} ({pct:5.2f}%)\")\n",
    "    print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SemEval Task 9 - Subtask 2: SIMPLIFIED Multi-Label\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nðŸ“Š English...\")\n",
    "    eng_train = load_data(Config.TRAIN_ENG, Config.LABELS)\n",
    "    eng_model, eng_tok, eng_f1, eng_t = train_model(\n",
    "        eng_train, 'english', Config.MODEL_ENG, Config.LR_ENG, Config\n",
    "    )\n",
    "    predict(eng_model, eng_tok, Config.DEV_ENG,\n",
    "           f\"{Config.PREDICTIONS_DIR}/pred_eng.csv\", eng_t, Config.LABELS, Config)\n",
    "\n",
    "    del eng_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\nðŸ“Š Kiswahili...\")\n",
    "    swa_train = load_data(Config.TRAIN_SWA, Config.LABELS)\n",
    "    swa_model, swa_tok, swa_f1, swa_t = train_model(\n",
    "        swa_train, 'kiswahili', Config.MODEL_SWA, Config.LR_SWA, Config\n",
    "    )\n",
    "    predict(swa_model, swa_tok, Config.DEV_SWA,\n",
    "           f\"{Config.PREDICTIONS_DIR}/pred_swa.csv\", swa_t, Config.LABELS, Config)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"English:   F1={eng_f1:.4f}\")\n",
    "    print(f\"Kiswahili: F1={swa_f1:.4f}\")\n",
    "    print(f\"Average:   {(eng_f1+swa_f1)/2:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nðŸ“¦ Creating submission...\")\n",
    "    !zip -r -q subtask_2.zip subtask_2\n",
    "    print(\"âœ… DONE!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
