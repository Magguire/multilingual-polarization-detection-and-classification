{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Device: cuda\n",
      "\n",
      "======================================================================\n",
      "SemEval Task 9 - Subtask 1: BALANCED APPROACH\n",
      "======================================================================\n",
      "\n",
      "Strategy:\n",
      "  â€¢ Moderate regularization (WD=0.02, Dropout=0.2)\n",
      "  â€¢ Light augmentation (25% prob, word swap only)\n",
      "  â€¢ Balanced sampling (weights^0.75)\n",
      "  â€¢ 12 epochs with patience=4\n",
      "  â€¢ Conservative threshold search\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š English...\n",
      "  Samples: 3222\n",
      "  Distribution: 0=2047, 1=1175 (ratio 1.7:1)\n",
      "\n",
      "======================================================================\n",
      "TRAINING: ENGLISH\n",
      "======================================================================\n",
      "Train: 2642, Val: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5633ee28bf6e4597a4a485372635f748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10eded76d1504ff7b830e0b957d1abaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.1091, F1=0.4517\n",
      "Val:   Loss=0.0986, F1=0.4076\n",
      "\n",
      "[Epoch 2/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac6ba9319f3441097ddbe2bd232b1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12670e8723de4bcfa92903004ea32aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0799, F1=0.7662\n",
      "Val:   Loss=0.0773, F1=0.7972\n",
      "\n",
      "[Epoch 3/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a23baaea15e4d60a0aeb2e50270f89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10931c9d128748ffa87d001fe180b42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0675, F1=0.8255\n",
      "Val:   Loss=0.0770, F1=0.7921\n",
      "\n",
      "[Epoch 4/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0a8a6659fa48a7b4e149240bea6e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5606581d933f4227b27170ede29e05f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0532, F1=0.8649\n",
      "Val:   Loss=0.0937, F1=0.8002\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc98697df7434fb3b504045f6b042a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.617(0.8162) 0.620(0.8162) 0.678(0.8152) \n",
      "  â†’ Best: Threshold=0.617, F1=0.8162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59a759e2854707954e3a4bf4b2fa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.8162, T=0.617)\n",
      "\n",
      "[Epoch 5/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c961d2e6f5eb41338b11043dc1407d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae75ff4179a496895154df9e0f93b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0475, F1=0.8868\n",
      "Val:   Loss=0.0963, F1=0.7997\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba2dc51092b4034a55f8f9709bd5452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.621(0.8181) 0.589(0.8167) 0.617(0.8164) \n",
      "  â†’ Best: Threshold=0.621, F1=0.8181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4917fe402ea8445ea02034c3195f2cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.8181, T=0.621)\n",
      "\n",
      "[Epoch 6/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab48f68c5eb44a7a64ae3180ad771b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466cf4963f2f4491bcb18e20489f55bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0402, F1=0.9049\n",
      "Val:   Loss=0.1286, F1=0.7664\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda51fb9908a4471a5e1965aa620d0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.699(0.8219) 0.703(0.8216) 0.706(0.8216) \n",
      "  â†’ Best: Threshold=0.699, F1=0.8219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98f8a057c448a481b4e73fade4cab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.8219, T=0.699)\n",
      "\n",
      "[Epoch 7/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ae832af63f42e38e9f69194c347213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dbd2bc52d647de94a30d2cec6e0b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0350, F1=0.9200\n",
      "Val:   Loss=0.1072, F1=0.8266\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0527f86f1d48b09bde6aed313c6533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.514(0.8293) 0.496(0.8286) 0.518(0.8273) \n",
      "  â†’ Best: Threshold=0.514, F1=0.8293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb8cdf0cdc54b33839c237e5be8921d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.8293, T=0.514)\n",
      "\n",
      "[Epoch 8/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2908759e810543498544e29c418cea43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47842639070749daa4fa92810544d0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0263, F1=0.9423\n",
      "Val:   Loss=0.1275, F1=0.8093\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e0f56ace294a0ca054ff88bdc13973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.388(0.8195) 0.391(0.8195) 0.381(0.8179) \n",
      "  â†’ Best: Threshold=0.388, F1=0.8195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255c56bdbe324ba0a5c429fe30ef6f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No improvement (1/4)\n",
      "\n",
      "[Epoch 9/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8f8a4daa3f45af98b88593378eed78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb96fae48e264a6eae914a4200e1812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    ^^self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^    ^if w.is_alive():^\n",
      "^^ ^  ^ ^ ^ ^ \n",
      "^^AssertionError^: ^^can only test a child process^\n",
      "^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0259, F1=0.9439\n",
      "Val:   Loss=0.1273, F1=0.8184\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185728a5c433445aa73382221f5f8f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.444(0.8246) 0.447(0.8246) 0.451(0.8246) \n",
      "  â†’ Best: Threshold=0.444, F1=0.8246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa854ee96cbc4b79ae85477f205dc243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No improvement (2/4)\n",
      "\n",
      "[Epoch 10/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83306c9c3bb64f8d806d00e5a066fcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67f41ae4b164d8b9dfdf1abc4eefb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0228, F1=0.9517\n",
      "Val:   Loss=0.1484, F1=0.8013\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a84f89ac4e4447ab7c76a619747aade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.416(0.8147) 0.375(0.8143) 0.279(0.8139) \n",
      "  â†’ Best: Threshold=0.416, F1=0.8147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baed97cab6d442d8b35346617d021d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No improvement (3/4)\n",
      "\n",
      "[Epoch 11/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdfb6c935bb477da8eecdc4f296b70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42468fca8b748b096df432fbdf68ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0178, F1=0.9612\n",
      "Val:   Loss=0.1605, F1=0.8080\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78878a18625d4b798c46f3739071ad40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.430(0.8172) 0.433(0.8172) 0.438(0.8168) \n",
      "  â†’ Best: Threshold=0.430, F1=0.8172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3494224ff0f740c780af3dcf7c68b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Pol     0.8556    0.8859    0.8705       368\n",
      "         Pol     0.7889    0.7406    0.7640       212\n",
      "\n",
      "    accuracy                         0.8328       580\n",
      "   macro avg     0.8223    0.8132    0.8172       580\n",
      "weighted avg     0.8313    0.8328    0.8316       580\n",
      "\n",
      "Per-class F1: Non-Pol=0.8705, Pol=0.7640\n",
      "  No improvement (4/4)\n",
      "Early stopping at epoch 11\n",
      "\n",
      "======================================================================\n",
      "FINAL: Val F1=0.8293, Threshold=0.514\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Predicting: /content/drive/MyDrive/NLP/subtask1/dev/eng.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5101df0bb02547a38d10a6f44f43c794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predict:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: /content/subtask_1/pred_eng.csv\n",
      "  Distribution: {0: np.int64(104), 1: np.int64(56)}, Pos: 35.0%\n",
      "\n",
      "\n",
      "ðŸ“Š Kiswahili...\n",
      "  Samples: 6991\n",
      "  Distribution: 0=3487, 1=3504 (ratio 1.0:1)\n",
      "\n",
      "======================================================================\n",
      "TRAINING: KISWAHILI\n",
      "======================================================================\n",
      "Train: 5732, Val: 1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad84b6d00be3453f947563f9ddc7a1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8623cf53aa34e9ea288e2e431908eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0988, F1=0.5148\n",
      "Val:   Loss=0.0868, F1=0.6844\n",
      "\n",
      "[Epoch 2/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c3fd46a2224c6592bbfc2efca32809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8e5fe50cc2493b9692c5854e22deb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0881, F1=0.6720\n",
      "Val:   Loss=0.0803, F1=0.7432\n",
      "\n",
      "[Epoch 3/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0a9d66f8f04e3e81343814ad404a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e95635a3d0d4c8cb11f35281e7f1730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0812, F1=0.7249\n",
      "Val:   Loss=0.0936, F1=0.7517\n",
      "\n",
      "[Epoch 4/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd50e8b55c04e3ba9b7fa7f6d6f3b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c093bab8af2b4c909407237c05ba61fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0711, F1=0.7738\n",
      "Val:   Loss=0.0878, F1=0.7443\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b34f3b9d5e547e4881e1daabca33cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.624(0.7619) 0.622(0.7612) 0.626(0.7611) \n",
      "  â†’ Best: Threshold=0.624, F1=0.7619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4075266d678b46548b2f9a776ce6c6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.7619, T=0.624)\n",
      "\n",
      "[Epoch 5/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7992049b58471aba794883fe0527c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2683b125624bd0bad415fe00f7409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0679, F1=0.7817\n",
      "Val:   Loss=0.0747, F1=0.7657\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf64c3d593b54c9eb8886609c6004fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.527(0.7788) 0.529(0.7787) 0.530(0.7786) \n",
      "  â†’ Best: Threshold=0.527, F1=0.7788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1e7a6fe4f7445b933c872729cfeb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.7788, T=0.527)\n",
      "\n",
      "[Epoch 6/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fcf2b16a7546c5b703ff244213bd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457d31ed9bda49d1aef08599e0bc95a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0632, F1=0.7895\n",
      "Val:   Loss=0.0776, F1=0.7648\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b49b2f9bcb445b1a8ef008ee338ee13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.571(0.7901) 0.564(0.7896) 0.568(0.7894) \n",
      "  â†’ Best: Threshold=0.571, F1=0.7901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f05e47cf054f7390e077ee882ae44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.7901, T=0.571)\n",
      "\n",
      "[Epoch 7/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c32636ee5d94ca5afa04d78754e3ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2562ffc052402eb7aae17ad6a9dea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0637, F1=0.7929\n",
      "Val:   Loss=0.0811, F1=0.7722\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63001ca36244e18a71ec545926fa740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.596(0.7904) 0.598(0.7896) 0.592(0.7889) \n",
      "  â†’ Best: Threshold=0.596, F1=0.7904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beaafe82c8074ca1834fb12ea5dd07fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.7904, T=0.596)\n",
      "\n",
      "[Epoch 8/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cef8377709e45c28829d3d53b46a925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7809461dbe8e4e1da502f9bd1985457a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0587, F1=0.8222\n",
      "Val:   Loss=0.0804, F1=0.7751\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc09b3915b0491e9c89cbc928b906b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.548(0.7827) 0.550(0.7826) 0.552(0.7817) \n",
      "  â†’ Best: Threshold=0.548, F1=0.7827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a28ec1b7211468e9c0e6cafbd8c0e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No improvement (1/4)\n",
      "\n",
      "[Epoch 9/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aab5ee199c94bfcb42b0ad32a6587f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520><function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "            ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "                   ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "AssertionError: can only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520><function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "   assert self._parent_pid == os.getpid(), 'can only test a child process'     \n",
      "             ^^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^AssertionError^: \n",
      "AssertionErrorcan only test a child process: \n",
      "can only test a child processException ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()    \n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "if w.is_alive():    if w.is_alive():\n",
      "\n",
      "            ^^ ^ ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "                  ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^AssertionError: \n",
      "AssertionErrorcan only test a child process: \n",
      "can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8ebdf348df4acf9c24c6a80b5ddcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0584, F1=0.8126\n",
      "Val:   Loss=0.0698, F1=0.7884\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad7afae4ca647f8b627b269056bcda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.497(0.7908) 0.523(0.7893) 0.499(0.7892) \n",
      "  â†’ Best: Threshold=0.497, F1=0.7908\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3650e297f04ef99060a3f5af8f1200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.7908, T=0.497)\n",
      "\n",
      "[Epoch 10/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad71eab6ccc426ca9c142301eb6cf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55af765fc16b4ee89b6d70233b42de0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0538, F1=0.8337\n",
      "Val:   Loss=0.0787, F1=0.7887\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79de3a4ab6604173b6263354dd974d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.583(0.7952) 0.581(0.7937) 0.585(0.7936) \n",
      "  â†’ Best: Threshold=0.583, F1=0.7952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a4c2efb507449fac0b5528cb8ca4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "     ^ ^ ^ ^ ^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      " ^  ^    ^ \n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "      ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^  ^^  ^^  ^ ^ ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      ": can only test a child process  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "\n",
      "    self._shutdown_workers()Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    if w.is_alive():\n",
      "self._shutdown_workers()   \n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "   ^   ^ ^ ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "     assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "              ^     ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: ^can only test a child process\n",
      "^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "^Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    ^self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "AssertionError    if w.is_alive():\n",
      " : can only test a child process \n",
      "  Exception ignored in:   \n",
      " <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>^^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^^^    ^^self._shutdown_workers()\n",
      "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    ^^if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "       assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "       ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^   ^  ^   ^ ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^AssertionError^: ^can only test a child process^^\n",
      "^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best (F1=0.7952, T=0.583)\n",
      "\n",
      "[Epoch 11/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d97a42c2294d3f9531517f4e7f1834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631814594a154fa49fa7abf7418d6850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0563, F1=0.8279\n",
      "Val:   Loss=0.0762, F1=0.7749\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b77d34c2d94aa5a87736c69e0a3f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "        ^ ^  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "if w.is_alive():    \n",
      " self._shutdown_workers() \n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "  ^   ^   ^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "\n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "       assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "            ^  ^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.592(0.7939) 0.586(0.7933) 0.588(0.7932) \n",
      "  â†’ Best: Threshold=0.592, F1=0.7939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ca6a531ecc4cccaeae9e32303a20ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Pol     0.7548    0.8726    0.8095       628\n",
      "         Pol     0.8499    0.7179    0.7784       631\n",
      "\n",
      "    accuracy                         0.7951      1259\n",
      "   macro avg     0.8024    0.7953    0.7939      1259\n",
      "weighted avg     0.8025    0.7951    0.7939      1259\n",
      "\n",
      "Per-class F1: Non-Pol=0.8095, Pol=0.7784\n",
      "  No improvement (1/4)\n",
      "\n",
      "[Epoch 12/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f5c6e100e442dabfad68d8d38eef2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfda7a36856c4b309b6ea18492b473eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e8cf0d02520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss=0.0529, F1=0.8348\n",
      "Val:   Loss=0.0779, F1=0.7770\n",
      "  Finding optimal threshold...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dcff342d874fd1b7e4c4d296dddcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Threshold:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 3: 0.617(0.7951) 0.600(0.7948) 0.605(0.7947) \n",
      "  â†’ Best: Threshold=0.617, F1=0.7951\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f5334456f345dc9d56fa8b173e2a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Pol     0.7514    0.8854    0.8129       628\n",
      "         Pol     0.8613    0.7084    0.7774       631\n",
      "\n",
      "    accuracy                         0.7967      1259\n",
      "   macro avg     0.8063    0.7969    0.7951      1259\n",
      "weighted avg     0.8064    0.7967    0.7951      1259\n",
      "\n",
      "Per-class F1: Non-Pol=0.8129, Pol=0.7774\n",
      "  No improvement (2/4)\n",
      "\n",
      "======================================================================\n",
      "FINAL: Val F1=0.7952, Threshold=0.583\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Predicting: /content/drive/MyDrive/NLP/subtask1/dev/swa.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9902c6a3d2fb4705a2daeef0dfe8c075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predict:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: /content/subtask_1/pred_swa.csv\n",
      "  Distribution: {0: np.int64(196), 1: np.int64(153)}, Pos: 43.8%\n",
      "\n",
      "\n",
      "======================================================================\n",
      "RESULTS\n",
      "======================================================================\n",
      "English:   Val F1=0.8293, Threshold=0.514\n",
      "Kiswahili: Val F1=0.7952, Threshold=0.583\n",
      "Average:   Val F1=0.8123\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¦ Creating submission...\n",
      "âœ… DONE!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SemEval Task 9 - Subtask 1: BALANCED APPROACH\n",
    "Target: 0.85+ on dev with <0.03 train/dev gap\n",
    "\n",
    "BALANCED STRATEGY:\n",
    "âœ“ Moderate regularization (not too strong, not too weak)\n",
    "âœ“ Light augmentation only for minority class\n",
    "âœ“ Better data sampling strategy\n",
    "âœ“ Optimal hyperparameters from literature\n",
    "âœ“ Focus on robust threshold tuning\n",
    "\"\"\"\n",
    "\n",
    "import os, pandas as pd, numpy as np, torch, torch.nn as nn\n",
    "import re, random, gc, warnings\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                         get_linear_schedule_with_warmup, set_seed)\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "set_seed(42)\n",
    "\n",
    "class Config:\n",
    "    BASE_PATH = '/content/drive/MyDrive/NLP'\n",
    "    TRAIN_ENG = f'{BASE_PATH}/subtask1/train/eng.csv'\n",
    "    TRAIN_SWA = f'{BASE_PATH}/subtask1/train/swa.csv'\n",
    "    DEV_ENG = f'{BASE_PATH}/subtask1/dev/eng.csv'\n",
    "    DEV_SWA = f'{BASE_PATH}/subtask1/dev/swa.csv'\n",
    "    OUTPUT_DIR = '/content/subtask1/models'\n",
    "    PREDICTIONS_DIR = '/content/subtask_1'\n",
    "    os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Models\n",
    "    MODEL_ENG = 'microsoft/deberta-v3-base'\n",
    "    MODEL_SWA = 'xlm-roberta-base'\n",
    "    MAX_LENGTH = 128\n",
    "\n",
    "    # BALANCED TRAINING - sweet spot\n",
    "    BATCH_SIZE = 16\n",
    "    GRAD_ACCUM = 2\n",
    "    EPOCHS = 12  # Moderate\n",
    "    LR_ENG = 1.5e-5  # Balanced LR\n",
    "    LR_SWA = 2e-5\n",
    "    WEIGHT_DECAY = 0.02  # Moderate weight decay\n",
    "    WARMUP_RATIO = 0.15\n",
    "    DROPOUT = 0.2  # Moderate dropout\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "\n",
    "    # Loss\n",
    "    FOCAL_ALPHA_ENG = 0.72\n",
    "    FOCAL_GAMMA_ENG = 2.2\n",
    "    FOCAL_ALPHA_SWA = 0.65\n",
    "    FOCAL_GAMMA_SWA = 2.2\n",
    "\n",
    "    # Validation\n",
    "    VAL_SIZE = 0.18\n",
    "\n",
    "    # Light augmentation\n",
    "    USE_AUGMENTATION = True\n",
    "    AUG_PROBABILITY = 0.25\n",
    "\n",
    "    USE_FP16 = True\n",
    "    SEED = 42\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device: {Config.DEVICE}\")\n",
    "\n",
    "class TextPreprocessor:\n",
    "    @staticmethod\n",
    "    def clean(text):\n",
    "        text = str(text).strip().lower()\n",
    "        text = re.sub(r'http\\S+|www\\.\\S+', ' [url] ', text)\n",
    "        text = re.sub(r'@\\w+', ' [user] ', text)\n",
    "        text = re.sub(r'#(\\w+)', r' \\1 ', text)\n",
    "        text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "        text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text if text else \"[empty]\"\n",
    "\n",
    "class LightAugmenter:\n",
    "    \"\"\"Very light augmentation - only word swapping\"\"\"\n",
    "    def __init__(self, p=0.25):\n",
    "        self.p = p\n",
    "        self.protected = {'not', 'no', 'never', 'but', 'however', 'although',\n",
    "                         '[url]', '[user]', 'only', 'all', 'always', 'never'}\n",
    "\n",
    "    def augment(self, text):\n",
    "        if random.random() > self.p:\n",
    "            return text\n",
    "\n",
    "        words = text.split()\n",
    "        if len(words) < 4:\n",
    "            return text\n",
    "\n",
    "        # Simple adjacent word swap\n",
    "        swappable = [i for i in range(len(words)-1)\n",
    "                    if words[i] not in self.protected and words[i+1] not in self.protected]\n",
    "\n",
    "        if swappable:\n",
    "            idx = random.choice(swappable)\n",
    "            words[idx], words[idx+1] = words[idx+1], words[idx]\n",
    "\n",
    "        return ' '.join(words)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.72, gamma=2.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets.float(), reduction='none'\n",
    "        )\n",
    "        pt = torch.exp(-bce)\n",
    "        loss = self.alpha * (1 - pt) ** self.gamma * bce\n",
    "        return loss.mean()\n",
    "\n",
    "class RobustModel(nn.Module):\n",
    "    def __init__(self, model_name, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.transformer = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=1,\n",
    "            hidden_dropout_prob=dropout,\n",
    "            attention_probs_dropout_prob=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "class PolarizationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len, augmenter=None, train=False):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.augmenter = augmenter\n",
    "        self.train = train\n",
    "        self.prep = TextPreprocessor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.prep.clean(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Light augmentation only for minority class during training\n",
    "        if self.train and self.augmenter and label == 1:\n",
    "            text = self.augmenter.augment(text)\n",
    "\n",
    "        enc = self.tokenizer(text, max_length=self.max_len, padding='max_length',\n",
    "                           truncation=True, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(TextPreprocessor.clean)\n",
    "    df = df[df['text'].str.len() > 0].reset_index(drop=True)\n",
    "    if 'polarization' in df.columns:\n",
    "        dist = df['polarization'].value_counts()\n",
    "        print(f\"  Samples: {len(df)}\")\n",
    "        print(f\"  Distribution: 0={dist[0]}, 1={dist[1]} (ratio {dist[0]/dist[1]:.1f}:1)\")\n",
    "    return df\n",
    "\n",
    "def find_threshold(model, loader, device, use_fp16=False):\n",
    "    print(\"  Finding optimal threshold...\")\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Threshold\", leave=False):\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            lbl = batch['label']\n",
    "\n",
    "            if use_fp16:\n",
    "                with autocast():\n",
    "                    out = model(ids, mask)\n",
    "                    p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "            else:\n",
    "                out = model(ids, mask)\n",
    "                p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "\n",
    "            probs.extend(p.cpu().numpy())\n",
    "            labels.extend(lbl.numpy())\n",
    "\n",
    "    probs, labels = np.array(probs), np.array(labels)\n",
    "\n",
    "    # Smart threshold search\n",
    "    pos_probs = probs[labels == 1]\n",
    "    neg_probs = probs[labels == 0]\n",
    "\n",
    "    if len(pos_probs) > 0 and len(neg_probs) > 0:\n",
    "        min_t = max(0.2, np.percentile(pos_probs, 10))\n",
    "        max_t = min(0.8, np.percentile(neg_probs, 90))\n",
    "    else:\n",
    "        min_t, max_t = 0.25, 0.75\n",
    "\n",
    "    thresholds = np.linspace(min_t, max_t, 121)\n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    results = []\n",
    "\n",
    "    for t in thresholds:\n",
    "        f1 = f1_score(labels, (probs >= t).astype(int), average='macro')\n",
    "        results.append((t, f1))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "\n",
    "    # Show top 3\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"  Top 3: \", end=\"\")\n",
    "    for i, (t, f) in enumerate(results[:3]):\n",
    "        print(f\"{t:.3f}({f:.4f})\", end=\" \")\n",
    "    print()\n",
    "    print(f\"  â†’ Best: Threshold={best_t:.3f}, F1={best_f1:.4f}\")\n",
    "\n",
    "    return best_t, best_f1\n",
    "\n",
    "def train_epoch(model, loader, opt, sched, crit, device, grad_accum, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    preds, labels = [], []\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"  Train\", leave=False)):\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        lbl = batch['label'].to(device)\n",
    "\n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                out = model(ids, mask)\n",
    "                loss = crit(out.logits.squeeze(-1), lbl) / grad_accum\n",
    "                p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "\n",
    "            batch_loss = loss.item() * grad_accum\n",
    "            preds.extend((p >= 0.5).long().cpu().numpy())\n",
    "            labels.extend(lbl.cpu().numpy())\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % grad_accum == 0:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad()\n",
    "        else:\n",
    "            out = model(ids, mask)\n",
    "            loss = crit(out.logits.squeeze(-1), lbl) / grad_accum\n",
    "\n",
    "            with torch.no_grad():\n",
    "                p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "\n",
    "            batch_loss = loss.item() * grad_accum\n",
    "            preds.extend((p >= 0.5).long().cpu().numpy())\n",
    "            labels.extend(lbl.cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % grad_accum == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                opt.step()\n",
    "                sched.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    return total_loss / len(loader), f1_score(labels, preds, average='macro')\n",
    "\n",
    "def evaluate(model, loader, crit, device, thresh=0.5, use_fp16=False, show_report=True):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Eval\", leave=False):\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            lbl = batch['label'].to(device)\n",
    "\n",
    "            if use_fp16:\n",
    "                with autocast():\n",
    "                    out = model(ids, mask)\n",
    "                    loss = crit(out.logits.squeeze(-1), lbl)\n",
    "            else:\n",
    "                out = model(ids, mask)\n",
    "                loss = crit(out.logits.squeeze(-1), lbl)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "            preds.extend((p >= thresh).long().cpu().numpy())\n",
    "            labels.extend(lbl.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "\n",
    "    if show_report:\n",
    "        f1_per_class = f1_score(labels, preds, average=None)\n",
    "        print(f\"\\n{classification_report(labels, preds, target_names=['Non-Pol','Pol'], digits=4)}\")\n",
    "        print(f\"Per-class F1: Non-Pol={f1_per_class[0]:.4f}, Pol={f1_per_class[1]:.4f}\")\n",
    "\n",
    "    return total_loss / len(loader), f1\n",
    "\n",
    "def train_model(train_df, lang, model_name, lr, alpha, gamma, config):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {lang.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Stratified split\n",
    "    train_data, val_data = train_test_split(\n",
    "        train_df, test_size=config.VAL_SIZE, random_state=config.SEED,\n",
    "        stratify=train_df['polarization']\n",
    "    )\n",
    "\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    aug = LightAugmenter(config.AUG_PROBABILITY) if config.USE_AUGMENTATION else None\n",
    "\n",
    "    train_ds = PolarizationDataset(train_data['text'].values, train_data['polarization'].values,\n",
    "                                   tokenizer, config.MAX_LENGTH, aug, True)\n",
    "    val_ds = PolarizationDataset(val_data['text'].values, val_data['polarization'].values,\n",
    "                                 tokenizer, config.MAX_LENGTH, None, False)\n",
    "\n",
    "    # Balanced sampling with moderate weighting\n",
    "    counts = np.bincount(train_data['polarization'].values)\n",
    "    weights = (1.0 / counts) ** 0.75  # Between sqrt(0.5) and 1.0\n",
    "    sample_weights = weights[train_data['polarization'].values]\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), True)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, config.BATCH_SIZE, sampler=sampler,\n",
    "                              num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, config.BATCH_SIZE*2, False,\n",
    "                           num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = RobustModel(model_name, config.DROPOUT).to(config.DEVICE)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr,\n",
    "                           weight_decay=config.WEIGHT_DECAY, eps=1e-8)\n",
    "\n",
    "    steps = len(train_loader) * config.EPOCHS // config.GRAD_ACCUM\n",
    "    warmup = int(steps * config.WARMUP_RATIO)\n",
    "    sched = get_linear_schedule_with_warmup(opt, warmup, steps)\n",
    "\n",
    "    crit = FocalLoss(alpha, gamma)\n",
    "    scaler = GradScaler() if config.USE_FP16 else None\n",
    "\n",
    "    best_f1, best_thresh = 0.0, 0.5\n",
    "    patience, p_cnt = 4, 0\n",
    "\n",
    "    for ep in range(config.EPOCHS):\n",
    "        print(f\"\\n[Epoch {ep+1}/{config.EPOCHS}]\")\n",
    "\n",
    "        tr_loss, tr_f1 = train_epoch(model, train_loader, opt, sched, crit,\n",
    "                                     config.DEVICE, config.GRAD_ACCUM, scaler)\n",
    "\n",
    "        # Quick eval without report\n",
    "        val_loss, val_f1 = evaluate(model, val_loader, crit, config.DEVICE, 0.5,\n",
    "                                    config.USE_FP16, show_report=False)\n",
    "\n",
    "        print(f\"Train: Loss={tr_loss:.4f}, F1={tr_f1:.4f}\")\n",
    "        print(f\"Val:   Loss={val_loss:.4f}, F1={val_f1:.4f}\")\n",
    "\n",
    "        # Find threshold from epoch 3\n",
    "        if ep >= 3:\n",
    "            thresh, _ = find_threshold(model, val_loader, config.DEVICE, config.USE_FP16)\n",
    "            _, val_f1 = evaluate(model, val_loader, crit, config.DEVICE, thresh,\n",
    "                               config.USE_FP16, show_report=(ep >= config.EPOCHS - 2))\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1, best_thresh, p_cnt = val_f1, thresh, 0\n",
    "                torch.save({\n",
    "                    'model': model.state_dict(),\n",
    "                    'threshold': float(thresh),\n",
    "                    'f1': float(val_f1)\n",
    "                }, f\"{config.OUTPUT_DIR}/best_{lang}.pt\", _use_new_zipfile_serialization=True)\n",
    "                print(f\"âœ“ Saved best (F1={best_f1:.4f}, T={best_thresh:.3f})\")\n",
    "            else:\n",
    "                p_cnt += 1\n",
    "                print(f\"  No improvement ({p_cnt}/{patience})\")\n",
    "\n",
    "        if ep >= 5 and p_cnt >= patience:\n",
    "            print(f\"Early stopping at epoch {ep+1}\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    ckpt = torch.load(f\"{config.OUTPUT_DIR}/best_{lang}.pt\", map_location=config.DEVICE, weights_only=False)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    best_f1 = ckpt['f1']\n",
    "    best_thresh = ckpt['threshold']\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FINAL: Val F1={best_f1:.4f}, Threshold={best_thresh:.3f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return model, tokenizer, best_f1, best_thresh\n",
    "\n",
    "def predict(model, tokenizer, test_file, out_file, thresh, config):\n",
    "    print(f\"\\nPredicting: {test_file}\")\n",
    "\n",
    "    df = pd.read_csv(test_file)\n",
    "    df['text'] = df['text'].apply(TextPreprocessor.clean)\n",
    "\n",
    "    ds = PolarizationDataset(df['text'].values, np.zeros(len(df)), tokenizer,\n",
    "                            config.MAX_LENGTH, None, False)\n",
    "    loader = DataLoader(ds, config.BATCH_SIZE*2, False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Predict\", leave=False):\n",
    "            ids = batch['input_ids'].to(config.DEVICE)\n",
    "            mask = batch['attention_mask'].to(config.DEVICE)\n",
    "\n",
    "            if config.USE_FP16:\n",
    "                with autocast():\n",
    "                    out = model(ids, mask)\n",
    "                    p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "            else:\n",
    "                out = model(ids, mask)\n",
    "                p = torch.sigmoid(out.logits.squeeze(-1))\n",
    "\n",
    "            preds.extend((p >= thresh).long().cpu().numpy())\n",
    "\n",
    "    out_df = pd.DataFrame({'id': df['id'], 'polarization': preds})\n",
    "    out_df.to_csv(out_file, index=False)\n",
    "\n",
    "    dist = pd.Series(preds).value_counts()\n",
    "    print(f\"âœ“ Saved: {out_file}\")\n",
    "    print(f\"  Distribution: {dict(dist)}, Pos: {dist.get(1,0)/len(preds)*100:.1f}%\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SemEval Task 9 - Subtask 1: BALANCED APPROACH\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nStrategy:\")\n",
    "    print(\"  â€¢ Moderate regularization (WD=0.02, Dropout=0.2)\")\n",
    "    print(\"  â€¢ Light augmentation (25% prob, word swap only)\")\n",
    "    print(\"  â€¢ Balanced sampling (weights^0.75)\")\n",
    "    print(\"  â€¢ 12 epochs with patience=4\")\n",
    "    print(\"  â€¢ Conservative threshold search\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nðŸ“Š English...\")\n",
    "    eng_train = load_data(Config.TRAIN_ENG)\n",
    "    eng_model, eng_tok, eng_f1, eng_t = train_model(\n",
    "        eng_train, 'english', Config.MODEL_ENG, Config.LR_ENG,\n",
    "        Config.FOCAL_ALPHA_ENG, Config.FOCAL_GAMMA_ENG, Config\n",
    "    )\n",
    "    predict(eng_model, eng_tok, Config.DEV_ENG,\n",
    "           f\"{Config.PREDICTIONS_DIR}/pred_eng.csv\", eng_t, Config)\n",
    "\n",
    "    del eng_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\nðŸ“Š Kiswahili...\")\n",
    "    swa_train = load_data(Config.TRAIN_SWA)\n",
    "    swa_model, swa_tok, swa_f1, swa_t = train_model(\n",
    "        swa_train, 'kiswahili', Config.MODEL_SWA, Config.LR_SWA,\n",
    "        Config.FOCAL_ALPHA_SWA, Config.FOCAL_GAMMA_SWA, Config\n",
    "    )\n",
    "    predict(swa_model, swa_tok, Config.DEV_SWA,\n",
    "           f\"{Config.PREDICTIONS_DIR}/pred_swa.csv\", swa_t, Config)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"English:   Val F1={eng_f1:.4f}, Threshold={eng_t:.3f}\")\n",
    "    print(f\"Kiswahili: Val F1={swa_f1:.4f}, Threshold={swa_t:.3f}\")\n",
    "    print(f\"Average:   Val F1={(eng_f1+swa_f1)/2:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nðŸ“¦ Creating submission...\")\n",
    "    !zip -r -q subtask_1.zip subtask_1\n",
    "    print(\"âœ… DONE!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
