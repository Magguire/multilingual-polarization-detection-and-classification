{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "ðŸš€ Device: cuda\n",
      "   GPU: Tesla T4\n",
      "   Memory: 15.8 GB\n",
      "\n",
      "======================================================================\n",
      "SemEval Task 9 - Subtask 3: FIXED\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Loading English data...\n",
      "  Samples: 3222\n",
      "  Label Distribution:\n",
      "    stereotype          :   487 (15.11%)\n",
      "    vilification        :   858 (26.63%)\n",
      "    dehumanization      :   391 (12.14%)\n",
      "    extreme_language    :   770 (23.90%)\n",
      "    lack_of_empathy     :   357 (11.08%)\n",
      "    invalidation        :   586 (18.19%)\n",
      "  Samples with â‰¥1 label: 1175 (36.5%)\n",
      "\n",
      "======================================================================\n",
      "TRAINING: ENGLISH\n",
      "======================================================================\n",
      "\n",
      "  Train: 2577, Val: 645\n",
      "\n",
      "  Class weights: {'stereotype': np.float64(1.0580733937007951), 'vilification': np.float64(0.7385401013138798), 'dehumanization': np.float64(1.195514130646282), 'extreme_language': np.float64(0.797726960126388), 'lack_of_empathy': np.float64(1.2752491751204493), 'invalidation': np.float64(0.9348962390922066)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3298909ae754f5da07935eb7ee16771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22102e644f0d49e2ba6b97c163c7c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d30b92d63410c812b9864fc88932d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1057e42fde9e4b3c863843528adbfb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c005df7ce9949e7b8f08efc424f79da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using Weighted Focal Loss (Î±=0.25, Î³=2.0)\n",
      "\n",
      "[Epoch 1/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fbaf9d876b414990621fc27ac54a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0494a7ebfa874cdfa8a011968f5cecc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.1070, F1=0.1998\n",
      "  Val:   Loss=0.0812, F1=0.0653 (thresh=0.5)\n",
      "\n",
      "[Epoch 2/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8263f4dcc54960bebd2947caee8419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052e8ffd19fd4105a754eba824fb9d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      " Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "     self._shutdown_workers()  \n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^^    if w.is_alive():^^\n",
      "^^  ^ ^^ ^^ ^ \n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      " ^  ^^  ^ ^ ^ ^^ ^^ \n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      " ^ ^  ^^ ^ ^^ ^ ^^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError: ^^can only test a child process\n",
      "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    ^self._shutdown_workers()^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^^    ^if w.is_alive():^\n",
      "  ^  ^ ^ ^ \n",
      "AssertionError^^: ^can only test a child process\n",
      "^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>^^\n",
      "Traceback (most recent call last):\n",
      "^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    self._shutdown_workers()\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "     if w.is_alive(): \n",
      "               ^ ^^^^^^^^^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^ ^^ ^ ^ ^  ^ ^^ ^ ^ ^ ^^^^^\n",
      "^AssertionError^: can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0534, F1=0.0535\n",
      "  Val:   Loss=0.0423, F1=0.0000 (thresh=0.5)\n",
      "\n",
      "[Epoch 3/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbab66c1cdee4760b641b74958637aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661c369146c04bb2803e0ba2dc11d027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0403, F1=0.0133\n",
      "  Val:   Loss=0.0374, F1=0.0000 (thresh=0.5)\n",
      "\n",
      "[Epoch 4/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd352bac6da445599deb951729dde7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f51179b1e34d52b4663ce8cb3d4b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0366, F1=0.0281\n",
      "  Val:   Loss=0.0378, F1=0.0000 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f34316dcd04141a85015df67eab8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    Exception ignored in: if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "      self._shutdown_workers() \n",
      "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      " ^    ^if w.is_alive():^\n",
      "^ ^^  ^^^ ^ ^^  \n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^ ^ ^  ^^   ^^   \n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^ ^^  ^ ^ ^ ^  ^^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^AssertionError^^: can only test a child process^\n",
      "^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    ^^self._shutdown_workers()^\n",
      "^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "AssertionError:     can only test a child processif w.is_alive():\n",
      "\n",
      " Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      " Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "      self._shutdown_workers()^\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^    ^^if w.is_alive():^\n",
      "^  ^^^ ^^\n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "     assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^ ^^ ^  ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError^: ^can only test a child process^^\n",
      "^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>^^\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    ^self._shutdown_workers()^\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^^    if w.is_alive():^\n",
      "^ \n",
      "AssertionError  :  can only test a child process\n",
      "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>  \n",
      "^^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    self._shutdown_workers()^\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^    ^if w.is_alive():^^^\n",
      "^ \n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "     assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^ ^ ^^  ^^ ^ ^ ^ ^  ^^^^^^^\n",
      "^AssertionError^: ^^can only test a child process^\n",
      "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>^\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^    ^^self._shutdown_workers()^^\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^^    ^if w.is_alive():^^\n",
      "^   ^ ^  ^ ^^^\n",
      "^^AssertionError: ^^can only test a child process^\n",
      "^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "^\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers() \n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "            ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.330, F1=0.4684 (pos=99)\n",
      "    vilification        : t=0.310, F1=0.6326 (pos=170)\n",
      "    dehumanization      : t=0.320, F1=0.4429 (pos=77)\n",
      "    extreme_language    : t=0.255, F1=0.6112 (pos=157)\n",
      "    lack_of_empathy     : t=0.255, F1=0.3562 (pos=77)\n",
      "    invalidation        : t=0.320, F1=0.4437 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5674ec7a8cb74f34bb51fcaa4b60a055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.4925\n",
      "  âœ“ Saved (F1=0.4925)\n",
      "\n",
      "[Epoch 5/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a10fb55a15496ea7f156b3e31ef814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ebceb8f72b4777bda2b8496d6e6e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0356, F1=0.0369\n",
      "  Val:   Loss=0.0374, F1=0.0000 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca004a22ade4289825b47dd38135e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.260, F1=0.4845 (pos=99)\n",
      "    vilification        : t=0.335, F1=0.6539 (pos=170)\n",
      "    dehumanization      : t=0.310, F1=0.4115 (pos=77)\n",
      "    extreme_language    : t=0.280, F1=0.6192 (pos=157)\n",
      "    lack_of_empathy     : t=0.215, F1=0.3750 (pos=77)\n",
      "    invalidation        : t=0.250, F1=0.4405 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6425764fee214a6b87d191760a3fa480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.4963\n",
      "  âœ“ Saved (F1=0.4963)\n",
      "\n",
      "[Epoch 6/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7463ea8e50f04bca8b201a859601e35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984364e821024255b1fb1c52d5e47c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0328, F1=0.0723\n",
      "  Val:   Loss=0.0382, F1=0.0019 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8725bc5609bf4085bfbb2292434cf99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.330, F1=0.4854 (pos=99)\n",
      "    vilification        : t=0.285, F1=0.6512 (pos=170)\n",
      "    dehumanization      : t=0.280, F1=0.4151 (pos=77)\n",
      "    extreme_language    : t=0.230, F1=0.6184 (pos=157)\n",
      "    lack_of_empathy     : t=0.205, F1=0.3730 (pos=77)\n",
      "    invalidation        : t=0.255, F1=0.4432 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a240534d4c134f178c7c7b37f872ee1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.4965\n",
      "  âœ“ Saved (F1=0.4965)\n",
      "\n",
      "[Epoch 7/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ac1a6a05af40368e4bf1f2d460bd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1412064e5b2461eb122c3bff7b56d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0324, F1=0.0754\n",
      "  Val:   Loss=0.0385, F1=0.0609 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802b4a7970f94c8baec68e596e500e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.235, F1=0.4805 (pos=99)\n",
      "    vilification        : t=0.290, F1=0.6620 (pos=170)\n",
      "    dehumanization      : t=0.310, F1=0.4138 (pos=77)\n",
      "    extreme_language    : t=0.270, F1=0.6203 (pos=157)\n",
      "    lack_of_empathy     : t=0.190, F1=0.3758 (pos=77)\n",
      "    invalidation        : t=0.245, F1=0.4468 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47267c39f65144d18ac2aae5b475b55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.4999\n",
      "  âœ“ Saved (F1=0.4999)\n",
      "\n",
      "[Epoch 8/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b452b0c30e47bb86958bce99ef019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298df05dde164377b395fd5029a7b504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0305, F1=0.1090\n",
      "  Val:   Loss=0.0407, F1=0.0530 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9f2f4bf24d4332b421a733caff84e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.325, F1=0.4840 (pos=99)\n",
      "    vilification        : t=0.225, F1=0.6511 (pos=170)\n",
      "    dehumanization      : t=0.315, F1=0.4138 (pos=77)\n",
      "    extreme_language    : t=0.215, F1=0.6139 (pos=157)\n",
      "    lack_of_empathy     : t=0.160, F1=0.3708 (pos=77)\n",
      "    invalidation        : t=0.195, F1=0.4479 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d974ea6aceb84b5aaffa2e231166071e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.4969\n",
      "  No improvement (1/4)\n",
      "\n",
      "[Epoch 9/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd5a1cfa3914358953969f9bce1ca2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7f2a89d764b8184a82c037ea47d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0297, F1=0.1216\n",
      "  Val:   Loss=0.0389, F1=0.0713 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f26100fbc44b93bdd0202e26747fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.350, F1=0.4821 (pos=99)\n",
      "    vilification        : t=0.275, F1=0.6544 (pos=170)\n",
      "    dehumanization      : t=0.305, F1=0.4098 (pos=77)\n",
      "    extreme_language    : t=0.260, F1=0.6203 (pos=157)\n",
      "    lack_of_empathy     : t=0.220, F1=0.3763 (pos=77)\n",
      "    invalidation        : t=0.235, F1=0.4479 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0cac9207624fde8b24fb8639e29f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.4985\n",
      "  No improvement (2/4)\n",
      "\n",
      "[Epoch 10/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08848ea279e9467aba24ce1e9aa0fc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa2ec4d356a4222a20624b1441d55a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "self._shutdown_workers()\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "    if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "       if w.is_alive(): \n",
      "     ^  ^ ^ ^ ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ ^   \n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "     assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "               ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "         if w.is_alive(): ^\n",
      "  ^^ ^ ^ ^^ ^ ^^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ ^ ^^^  \n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "      assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^ ^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError: ^^\n",
      "can only test a child processAssertionError\n",
      ": Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "            ^ ^^^^ ^^^^^^^^^^^^^^^^\n",
      "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "                ^^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError\n",
      "AssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520><function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "if w.is_alive():\n",
      "             ^^ ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: \n",
      "can only test a child process\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0298, F1=0.1292\n",
      "  Val:   Loss=0.0401, F1=0.0735 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b85bf12f27420c83250aa44cfb16f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.335, F1=0.4933 (pos=99)\n",
      "    vilification        : t=0.240, F1=0.6560 (pos=170)\n",
      "    dehumanization      : t=0.280, F1=0.4171 (pos=77)\n",
      "    extreme_language    : t=0.260, F1=0.6211 (pos=157)\n",
      "    lack_of_empathy     : t=0.200, F1=0.3737 (pos=77)\n",
      "    invalidation        : t=0.210, F1=0.4503 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040752add4f64dcd9658c19f53c70817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5015\n",
      "  âœ“ Saved (F1=0.5015)\n",
      "\n",
      "[Epoch 11/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4460d71f74a747e79d647bd25c1cefb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82221d469dae4210a3eea3a7f3243266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0290, F1=0.1255\n",
      "  Val:   Loss=0.0394, F1=0.0792 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2eb5541b084a39a4299ce3f4e4f533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.350, F1=0.4825 (pos=99)\n",
      "    vilification        : t=0.270, F1=0.6544 (pos=170)\n",
      "    dehumanization      : t=0.295, F1=0.4163 (pos=77)\n",
      "    extreme_language    : t=0.265, F1=0.6205 (pos=157)\n",
      "    lack_of_empathy     : t=0.225, F1=0.3803 (pos=77)\n",
      "    invalidation        : t=0.240, F1=0.4485 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b416c374bd574e649a277af3aaf99ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Per-label Performance:\n",
      "    stereotype          : F1=0.4825 (pred= 129, true=  99)\n",
      "    vilification        : F1=0.6544 (pred= 264, true= 170)\n",
      "    dehumanization      : F1=0.4144 (pred= 145, true=  77)\n",
      "    extreme_language    : F1=0.6205 (pred= 233, true= 157)\n",
      "    lack_of_empathy     : F1=0.3803 (pred= 207, true=  77)\n",
      "    invalidation        : F1=0.4485 (pred= 270, true= 109)\n",
      "\n",
      "  Macro F1: 0.5001\n",
      "  Val with tuned thresholds: F1=0.5001\n",
      "  No improvement (1/4)\n",
      "\n",
      "[Epoch 12/12]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b14ad81a8c4cd391c03fa478915338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71ca81e85144ab285ba651abca9323a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0289, F1=0.1368\n",
      "  Val:   Loss=0.0395, F1=0.0808 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e137c72e53424daf93eca5caefed2d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.350, F1=0.4825 (pos=99)\n",
      "    vilification        : t=0.270, F1=0.6544 (pos=170)\n",
      "    dehumanization      : t=0.295, F1=0.4144 (pos=77)\n",
      "    extreme_language    : t=0.265, F1=0.6205 (pos=157)\n",
      "    lack_of_empathy     : t=0.225, F1=0.3803 (pos=77)\n",
      "    invalidation        : t=0.195, F1=0.4493 (pos=109)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdb3e3f83664578893cfff93cad5002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Per-label Performance:\n",
      "    stereotype          : F1=0.4825 (pred= 129, true=  99)\n",
      "    vilification        : F1=0.6544 (pred= 264, true= 170)\n",
      "    dehumanization      : F1=0.4144 (pred= 145, true=  77)\n",
      "    extreme_language    : F1=0.6205 (pred= 233, true= 157)\n",
      "    lack_of_empathy     : F1=0.3803 (pred= 207, true=  77)\n",
      "    invalidation        : F1=0.4493 (pred= 305, true= 109)\n",
      "\n",
      "  Macro F1: 0.5002\n",
      "  Val with tuned thresholds: F1=0.5002\n",
      "  No improvement (2/4)\n",
      "\n",
      "======================================================================\n",
      "FINAL: ENGLISH F1-Macro=0.5015\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Predicting: /content/drive/MyDrive/NLP/subtask3/dev/eng.csv\n",
      "  Using multi-sample dropout (5 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24521358d9404cc284818d7c73f162c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predict:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: /content/subtask_3/pred_eng.csv\n",
      "  Prediction Statistics:\n",
      "    stereotype          :    29 (18.12%) [t=0.335]\n",
      "    vilification        :    67 (41.88%) [t=0.240]\n",
      "    dehumanization      :    33 (20.62%) [t=0.280]\n",
      "    extreme_language    :    62 (38.75%) [t=0.260]\n",
      "    lack_of_empathy     :    60 (37.50%) [t=0.200]\n",
      "    invalidation        :    72 (45.00%) [t=0.210]\n",
      "\n",
      "ðŸ“Š Loading Kiswahili data...\n",
      "  Samples: 6991\n",
      "  Label Distribution:\n",
      "    stereotype          :  2775 (39.69%)\n",
      "    vilification        :  2883 (41.24%)\n",
      "    dehumanization      :   893 (12.77%)\n",
      "    extreme_language    :  1673 (23.93%)\n",
      "    lack_of_empathy     :  2080 (29.75%)\n",
      "    invalidation        :  1637 (23.42%)\n",
      "  Samples with â‰¥1 label: 3504 (50.1%)\n",
      "\n",
      "======================================================================\n",
      "TRAINING: KISWAHILI\n",
      "======================================================================\n",
      "\n",
      "  Train: 5592, Val: 1399\n",
      "\n",
      "  Class weights: {'stereotype': np.float64(0.7271160028929861), 'vilification': np.float64(0.7100589937065583), 'dehumanization': np.float64(1.5298572523054663), 'extreme_language': np.float64(1.0455265837024814), 'lack_of_empathy': np.float64(0.9126916119860159), 'invalidation': np.float64(1.0747495554064916)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1777263c725545558503cb9b3399086e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc229c3c95f49c183419cf44ab85bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d960fa1adc74c9fa122724c9f32b6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e13fe99ad2f4250991f1752cd73a9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11286b9dabad4b1b8dc434a92ebebdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using Weighted Focal Loss (Î±=0.25, Î³=2.0)\n",
      "\n",
      "[Epoch 1/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edb6ebe7120433e8a32cad9ce698032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0025cfb0f34a2cafa24aa8ec156d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0787, F1=0.2229\n",
      "  Val:   Loss=0.0533, F1=0.0000 (thresh=0.5)\n",
      "\n",
      "[Epoch 2/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ec428dc8124b05a117c5a07d014afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac1b4c55ca8439ca0519bcf01ee7d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0565, F1=0.0049\n",
      "  Val:   Loss=0.0512, F1=0.0000 (thresh=0.5)\n",
      "\n",
      "[Epoch 3/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc095db10fd14d29a9402bf0e8fba429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85512de6ffd45a883899113a4d51453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0527, F1=0.0266\n",
      "  Val:   Loss=0.0481, F1=0.0000 (thresh=0.5)\n",
      "\n",
      "[Epoch 4/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3590540df1c64d30b00ca4c11569e7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727fb3bf41d94a2d897de25986118b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0491, F1=0.1055\n",
      "  Val:   Loss=0.0462, F1=0.1791 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2d7fc59add4cd280d7ca996fd2de85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.390, F1=0.6839 (pos=541)\n",
      "    vilification        : t=0.380, F1=0.7031 (pos=585)\n",
      "    dehumanization      : t=0.265, F1=0.3015 (pos=163)\n",
      "    extreme_language    : t=0.295, F1=0.4637 (pos=312)\n",
      "    lack_of_empathy     : t=0.305, F1=0.5784 (pos=420)\n",
      "    invalidation        : t=0.360, F1=0.5226 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce9ec1106e64631857f1d1fd7ad8fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5421\n",
      "  âœ“ Saved (F1=0.5421)\n",
      "\n",
      "[Epoch 5/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f569e3c0d1e48c6b2ebe6b6a62be004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaab21b5bd64bf2a3b12f2d36336470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0467, F1=0.1642\n",
      "  Val:   Loss=0.0466, F1=0.1894 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02d952244bc477189f5f2b51e7125d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.330, F1=0.6736 (pos=541)\n",
      "    vilification        : t=0.355, F1=0.7162 (pos=585)\n",
      "    dehumanization      : t=0.255, F1=0.3063 (pos=163)\n",
      "    extreme_language    : t=0.305, F1=0.4844 (pos=312)\n",
      "    lack_of_empathy     : t=0.320, F1=0.6031 (pos=420)\n",
      "    invalidation        : t=0.355, F1=0.5177 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c87437d09849659000a9259f776465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5502\n",
      "  âœ“ Saved (F1=0.5502)\n",
      "\n",
      "[Epoch 6/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db24127b27cb4893a8b05e51110495bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a12746f9efa469ab982444129e5f74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0448, F1=0.1861\n",
      "  Val:   Loss=0.0464, F1=0.2081 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b738b59d96a2462588bb55c8b2361f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.375, F1=0.6785 (pos=541)\n",
      "    vilification        : t=0.380, F1=0.7264 (pos=585)\n",
      "    dehumanization      : t=0.305, F1=0.3092 (pos=163)\n",
      "    extreme_language    : t=0.350, F1=0.4910 (pos=312)\n",
      "    lack_of_empathy     : t=0.330, F1=0.6096 (pos=420)\n",
      "    invalidation        : t=0.370, F1=0.5345 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd77a3169be43498735fe44d7ddb84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5581\n",
      "  âœ“ Saved (F1=0.5581)\n",
      "\n",
      "[Epoch 7/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d104b9b19a214cf795da414b6f16851d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6e3950d3f04ff0b546bfdc7eb6944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0428, F1=0.2047\n",
      "  Val:   Loss=0.0473, F1=0.2209 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42902d51baa9482399b6638b2d69829d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.435, F1=0.6829 (pos=541)\n",
      "    vilification        : t=0.460, F1=0.7303 (pos=585)\n",
      "    dehumanization      : t=0.315, F1=0.3007 (pos=163)\n",
      "    extreme_language    : t=0.385, F1=0.4843 (pos=312)\n",
      "    lack_of_empathy     : t=0.365, F1=0.6011 (pos=420)\n",
      "    invalidation        : t=0.385, F1=0.5370 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4850100e3d2542308e611dd0e44180a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5557\n",
      "  No improvement (1/4)\n",
      "\n",
      "[Epoch 8/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f249881fa4c843889d6161855aa2e385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d982fccf1941469aca8c4777c9bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0416, F1=0.2174\n",
      "  Val:   Loss=0.0473, F1=0.2340 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36cd890eb4747e08d0ec4a2067f74f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.370, F1=0.6770 (pos=541)\n",
      "    vilification        : t=0.390, F1=0.7240 (pos=585)\n",
      "    dehumanization      : t=0.290, F1=0.2943 (pos=163)\n",
      "    extreme_language    : t=0.355, F1=0.4894 (pos=312)\n",
      "    lack_of_empathy     : t=0.365, F1=0.5961 (pos=420)\n",
      "    invalidation        : t=0.380, F1=0.5304 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0a1171650f48e8baf75d152d6cbd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5519\n",
      "  No improvement (2/4)\n",
      "\n",
      "[Epoch 9/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b9705b27d24791a2a7a4a157c48594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9630b6b57d3841b0ad0ed3056fb1c64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0396, F1=0.2558\n",
      "  Val:   Loss=0.0485, F1=0.2422 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74263dbc028d471b81ce8e4b00fd7e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.360, F1=0.6737 (pos=541)\n",
      "    vilification        : t=0.420, F1=0.7235 (pos=585)\n",
      "    dehumanization      : t=0.255, F1=0.2988 (pos=163)\n",
      "    extreme_language    : t=0.350, F1=0.4911 (pos=312)\n",
      "    lack_of_empathy     : t=0.380, F1=0.6012 (pos=420)\n",
      "    invalidation        : t=0.340, F1=0.5318 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d14ae8b9e84424b4dc58a4b923ddb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5532\n",
      "  No improvement (3/4)\n",
      "\n",
      "[Epoch 10/15]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6a600f159647dca6e3ff44e61bada1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Train:   0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f921a912ec914d1bbaa39683a569420d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: Loss=0.0385, F1=0.2874\n",
      "  Val:   Loss=0.0503, F1=0.2532 (thresh=0.5)\n",
      "  Finding optimal thresholds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eac30b96a4c4d82897a10130d4a76ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Collecting:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ebbf2b72520>\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "^^    ^self._shutdown_workers()\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "^    ^if w.is_alive():^\n",
      "^ ^^  ^  ^^  ^\n",
      "AssertionError^: can only test a child process^\n",
      "^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stereotype          : t=0.375, F1=0.6641 (pos=541)\n",
      "    vilification        : t=0.380, F1=0.7107 (pos=585)\n",
      "    dehumanization      : t=0.285, F1=0.2944 (pos=163)\n",
      "    extreme_language    : t=0.305, F1=0.4715 (pos=312)\n",
      "    lack_of_empathy     : t=0.380, F1=0.5869 (pos=420)\n",
      "    invalidation        : t=0.360, F1=0.5089 (pos=332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e385d5db38642de9b7d30477d40dd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Eval:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val with tuned thresholds: F1=0.5394\n",
      "  No improvement (4/4)\n",
      "  Early stopping at epoch 10\n",
      "\n",
      "======================================================================\n",
      "FINAL: KISWAHILI F1-Macro=0.5581\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Predicting: /content/drive/MyDrive/NLP/subtask3/dev/swa.csv\n",
      "  Using multi-sample dropout (5 samples)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28d32e5e26e4109b8971c1f56585c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predict:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: /content/subtask_3/pred_swa.csv\n",
      "  Prediction Statistics:\n",
      "    stereotype          :   142 (40.69%) [t=0.375]\n",
      "    vilification        :   145 (41.55%) [t=0.380]\n",
      "    dehumanization      :    56 (16.05%) [t=0.305]\n",
      "    extreme_language    :   100 (28.65%) [t=0.350]\n",
      "    lack_of_empathy     :   147 (42.12%) [t=0.330]\n",
      "    invalidation        :    84 (24.07%) [t=0.370]\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n",
      "English:   Val F1=0.5015\n",
      "Kiswahili: Val F1=0.5581\n",
      "Average:   0.5298\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¦ Creating submission...\n",
      "âœ… DONE! Download subtask_3.zip\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SemEval Task 9 - Subtask 3: FIXED Manifestation Classification\n",
    "Target: 0.65+ F1-Macro (realistic for extreme imbalance)\n",
    "\n",
    "CRITICAL FIXES:\n",
    "âœ“ Fixed scipy float16 error\n",
    "âœ“ Focal Loss instead of Asymmetric (more stable)\n",
    "âœ“ Smaller models to prevent overfitting\n",
    "âœ“ Label-wise class weights\n",
    "âœ“ Fixed multi-sample dropout implementation\n",
    "âœ“ Better threshold tuning\n",
    "âœ“ Strong regularization\n",
    "\"\"\"\n",
    "\n",
    "import os, pandas as pd, numpy as np, torch, torch.nn as nn\n",
    "import re, random, gc, warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import (AutoTokenizer, AutoModel,\n",
    "                         get_cosine_schedule_with_warmup, set_seed)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "set_seed(42)\n",
    "\n",
    "class Config:\n",
    "    BASE_PATH = '/content/drive/MyDrive/NLP'\n",
    "    TRAIN_ENG = f'{BASE_PATH}/subtask3/train/eng.csv'\n",
    "    TRAIN_SWA = f'{BASE_PATH}/subtask3/train/swa.csv'\n",
    "    DEV_ENG = f'{BASE_PATH}/subtask3/dev/eng.csv'\n",
    "    DEV_SWA = f'{BASE_PATH}/subtask3/dev/swa.csv'\n",
    "    OUTPUT_DIR = '/content/subtask3/models'\n",
    "    PREDICTIONS_DIR = '/content/subtask_3'\n",
    "    os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Smaller models to prevent overfitting\n",
    "    MODEL_ENG = 'microsoft/deberta-v3-small'  # 44M params\n",
    "    MODEL_SWA = 'xlm-roberta-base'  # 270M params\n",
    "    MAX_LENGTH = 128\n",
    "\n",
    "    LABELS = ['stereotype', 'vilification', 'dehumanization',\n",
    "              'extreme_language', 'lack_of_empathy', 'invalidation']\n",
    "    NUM_LABELS = 6\n",
    "\n",
    "    # More aggressive regularization\n",
    "    BATCH_SIZE_ENG = 16\n",
    "    BATCH_SIZE_SWA = 12\n",
    "    GRAD_ACCUM = 2\n",
    "    EPOCHS_ENG = 12\n",
    "    EPOCHS_SWA = 15\n",
    "    LR_ENG = 8e-6  # Lower LR\n",
    "    LR_SWA = 1e-5\n",
    "    WEIGHT_DECAY = 0.08  # Higher weight decay\n",
    "    WARMUP_RATIO = 0.15\n",
    "    DROPOUT = 0.35  # Higher dropout\n",
    "    MAX_GRAD_NORM = 0.5\n",
    "\n",
    "    # Focal Loss parameters\n",
    "    FOCAL_ALPHA = 0.25  # Weight for positive class\n",
    "    FOCAL_GAMMA = 2.0   # Focusing parameter\n",
    "\n",
    "    # Inference\n",
    "    INFERENCE_SAMPLES = 5  # Multi-sample dropout\n",
    "\n",
    "    VAL_SIZE = 0.20\n",
    "    USE_FP16 = True\n",
    "    SEED = 42\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"ðŸš€ Device: {Config.DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================================\n",
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.contractions = {\n",
    "            \"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\",\n",
    "            \"won't\": \"will not\", \"don't\": \"do not\", \"didn't\": \"did not\",\n",
    "            \"hasn't\": \"has not\", \"haven't\": \"have not\", \"isn't\": \"is not\",\n",
    "            \"wasn't\": \"was not\", \"weren't\": \"were not\", \"shouldn't\": \"should not\",\n",
    "            \"wouldn't\": \"would not\", \"couldn't\": \"could not\",\n",
    "        }\n",
    "\n",
    "    def clean(self, text):\n",
    "        text = str(text).strip()\n",
    "        if not text:\n",
    "            return \"[empty]\"\n",
    "\n",
    "        # Preserve case for better semantic understanding\n",
    "        text = re.sub(r'http\\S+|www\\.\\S+', '[url]', text)\n",
    "        text = re.sub(r'@\\w+', '[user]', text)\n",
    "        text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "        text = re.sub(r'(.)\\1{3,}', r'\\1\\1', text)\n",
    "\n",
    "        # Expand contractions\n",
    "        for c, e in self.contractions.items():\n",
    "            text = re.sub(r'\\b' + c + r'\\b', e, text, flags=re.IGNORECASE)\n",
    "\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text if text else \"[empty]\"\n",
    "\n",
    "# ============================================================================\n",
    "# FOCAL LOSS (More stable than Asymmetric)\n",
    "# ============================================================================\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for handling class imbalance\n",
    "    More stable than Asymmetric Loss\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Convert to float32 to avoid scipy issues\n",
    "        logits = logits.float()\n",
    "        targets = targets.float()\n",
    "\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction='none'\n",
    "        )\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        focal_weight = alpha_t * (1 - p_t) ** self.gamma\n",
    "\n",
    "        loss = focal_weight * bce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "# ============================================================================\n",
    "# CLASS-WEIGHTED FOCAL LOSS\n",
    "# ============================================================================\n",
    "class WeightedFocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss with per-label class weights\"\"\"\n",
    "    def __init__(self, label_weights, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.label_weights = torch.tensor(label_weights, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        logits = logits.float()\n",
    "        targets = targets.float()\n",
    "\n",
    "        device = logits.device\n",
    "        if self.label_weights.device != device:\n",
    "            self.label_weights = self.label_weights.to(device)\n",
    "\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction='none'\n",
    "        )\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        focal_weight = alpha_t * (1 - p_t) ** self.gamma\n",
    "\n",
    "        # Apply label-wise weights\n",
    "        weighted_loss = focal_weight * bce_loss * self.label_weights\n",
    "\n",
    "        return weighted_loss.mean()\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL\n",
    "# ============================================================================\n",
    "class MultiLabelModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=6, dropout=0.35):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "\n",
    "        # Classification head with extra dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.8),\n",
    "            nn.Linear(hidden_size // 2, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len, label_names):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label_names = label_names\n",
    "        self.prep = TextPreprocessor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.prep.clean(self.texts[idx])\n",
    "        label_vector = self.labels.iloc[idx][self.label_names].values.astype(np.float32)\n",
    "\n",
    "        enc = self.tokenizer(text, max_length=self.max_len, padding='max_length',\n",
    "                           truncation=True, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label_vector, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITIES\n",
    "# ============================================================================\n",
    "def load_data(path, label_names):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(TextPreprocessor().clean)\n",
    "    df = df[df['text'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "    print(f\"  Samples: {len(df)}\")\n",
    "    print(f\"  Label Distribution:\")\n",
    "\n",
    "    for label in label_names:\n",
    "        count = df[label].sum()\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"    {label:20s}: {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "    label_matrix = df[label_names].values\n",
    "    samples_with_labels = (label_matrix.sum(axis=1) > 0).sum()\n",
    "    print(f\"  Samples with â‰¥1 label: {samples_with_labels} ({samples_with_labels/len(df)*100:.1f}%)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_class_weights(df, label_names):\n",
    "    \"\"\"Compute inverse frequency weights for each label\"\"\"\n",
    "    weights = []\n",
    "    total = len(df)\n",
    "\n",
    "    for label in label_names:\n",
    "        pos_count = df[label].sum()\n",
    "        if pos_count == 0:\n",
    "            weight = 1.0\n",
    "        else:\n",
    "            # Inverse frequency with smoothing\n",
    "            neg_count = total - pos_count\n",
    "            weight = np.sqrt(neg_count / (pos_count + 1))\n",
    "        weights.append(weight)\n",
    "\n",
    "    # Normalize\n",
    "    weights = np.array(weights)\n",
    "    weights = weights / weights.mean()\n",
    "\n",
    "    return weights\n",
    "\n",
    "def find_optimal_thresholds(model, loader, device, label_names, use_fp16=False):\n",
    "    \"\"\"Find optimal threshold for each label\"\"\"\n",
    "    print(\"  Finding optimal thresholds...\")\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Collecting\", leave=False):\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels']\n",
    "\n",
    "            if use_fp16:\n",
    "                with autocast():\n",
    "                    logits = model(ids, mask)\n",
    "                    probs = torch.sigmoid(logits)\n",
    "            else:\n",
    "                logits = model(ids, mask)\n",
    "                probs = torch.sigmoid(logits)\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.numpy())\n",
    "\n",
    "    all_probs = np.vstack(all_probs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    thresholds = []\n",
    "\n",
    "    for i, label in enumerate(label_names):\n",
    "        label_probs = all_probs[:, i]\n",
    "        label_true = all_labels[:, i]\n",
    "\n",
    "        pos_count = int(label_true.sum())\n",
    "\n",
    "        if pos_count < 3:\n",
    "            thresh = 0.7\n",
    "            thresholds.append(thresh)\n",
    "            print(f\"    {label:20s}: too few ({pos_count}), using t={thresh:.3f}\")\n",
    "            continue\n",
    "\n",
    "        # Search threshold space\n",
    "        thresh_range = np.linspace(0.1, 0.9, 161)\n",
    "        best_t, best_f1 = 0.5, 0.0\n",
    "\n",
    "        for t in thresh_range:\n",
    "            preds = (label_probs >= t).astype(np.float32)\n",
    "            f1 = f1_score(label_true, preds, average='binary', zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "\n",
    "        # Conservative fallback for low F1\n",
    "        if best_f1 < 0.1 and pos_count < 20:\n",
    "            best_t = 0.65\n",
    "\n",
    "        thresholds.append(best_t)\n",
    "        print(f\"    {label:20s}: t={best_t:.3f}, F1={best_f1:.4f} (pos={pos_count})\")\n",
    "\n",
    "    return thresholds\n",
    "\n",
    "def train_epoch(model, loader, opt, sched, crit, device, grad_accum, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"  Train\", leave=False)):\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                logits = model(ids, mask)\n",
    "                loss = crit(logits, labels) / grad_accum\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Collect predictions in fp32\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(logits.float())\n",
    "                all_preds.append((probs >= 0.5).long().cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            if (step + 1) % grad_accum == 0:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad()\n",
    "        else:\n",
    "            logits = model(ids, mask)\n",
    "            loss = crit(logits, labels) / grad_accum\n",
    "\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(logits)\n",
    "                all_preds.append((probs >= 0.5).long().cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % grad_accum == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n",
    "                opt.step()\n",
    "                sched.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * grad_accum\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return total_loss / len(loader), f1_macro\n",
    "\n",
    "def evaluate(model, loader, crit, device, thresholds, label_names, use_fp16=False, show_report=True):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"  Eval\", leave=False):\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            if use_fp16:\n",
    "                with autocast():\n",
    "                    logits = model(ids, mask)\n",
    "                    loss = crit(logits, labels)\n",
    "                    probs = torch.sigmoid(logits.float())\n",
    "            else:\n",
    "                logits = model(ids, mask)\n",
    "                loss = crit(logits, labels)\n",
    "                probs = torch.sigmoid(logits)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.vstack(all_probs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "\n",
    "    # Apply per-label thresholds\n",
    "    all_preds = np.zeros_like(all_probs)\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        all_preds[:, i] = (all_probs[:, i] >= thresh).astype(float)\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    if show_report:\n",
    "        print(\"\\n  Per-label Performance:\")\n",
    "        for i, label in enumerate(label_names):\n",
    "            f1 = f1_score(all_labels[:, i], all_preds[:, i], average='binary', zero_division=0)\n",
    "            pred_pos = all_preds[:, i].sum()\n",
    "            true_pos = all_labels[:, i].sum()\n",
    "            print(f\"    {label:20s}: F1={f1:.4f} (pred={int(pred_pos):4d}, true={int(true_pos):4d})\")\n",
    "        print(f\"\\n  Macro F1: {f1_macro:.4f}\")\n",
    "\n",
    "    return total_loss / len(loader), f1_macro\n",
    "\n",
    "def train_model(train_df, lang, model_name, lr, batch_size, epochs, config):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {lang.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Split\n",
    "    has_label = (train_df[config.LABELS].sum(axis=1) > 0).astype(int)\n",
    "    train_data, val_data = train_test_split(\n",
    "        train_df, test_size=config.VAL_SIZE, random_state=config.SEED,\n",
    "        stratify=has_label\n",
    "    )\n",
    "\n",
    "    print(f\"\\n  Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weights(train_data, config.LABELS)\n",
    "    print(f\"\\n  Class weights: {dict(zip(config.LABELS, class_weights))}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_ds = MultiLabelDataset(train_data['text'].values, train_data, tokenizer,\n",
    "                                 config.MAX_LENGTH, config.LABELS)\n",
    "    val_ds = MultiLabelDataset(val_data['text'].values, val_data, tokenizer,\n",
    "                               config.MAX_LENGTH, config.LABELS)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size, shuffle=True,\n",
    "                              num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size*2, shuffle=False,\n",
    "                           num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = MultiLabelModel(model_name, config.NUM_LABELS, config.DROPOUT).to(config.DEVICE)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr,\n",
    "                           weight_decay=config.WEIGHT_DECAY, eps=1e-8)\n",
    "\n",
    "    steps = len(train_loader) * epochs // config.GRAD_ACCUM\n",
    "    warmup = int(steps * config.WARMUP_RATIO)\n",
    "    sched = get_cosine_schedule_with_warmup(opt, warmup, steps)\n",
    "\n",
    "    # Use Weighted Focal Loss\n",
    "    crit = WeightedFocalLoss(class_weights, alpha=config.FOCAL_ALPHA, gamma=config.FOCAL_GAMMA)\n",
    "    print(f\"\\n  Using Weighted Focal Loss (Î±={config.FOCAL_ALPHA}, Î³={config.FOCAL_GAMMA})\")\n",
    "\n",
    "    scaler = GradScaler() if config.USE_FP16 else None\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_thresholds = [0.5] * config.NUM_LABELS\n",
    "    patience, p_cnt = 4, 0\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(f\"\\n[Epoch {ep+1}/{epochs}]\")\n",
    "\n",
    "        tr_loss, tr_f1 = train_epoch(model, train_loader, opt, sched, crit,\n",
    "                                     config.DEVICE, config.GRAD_ACCUM, scaler)\n",
    "\n",
    "        val_loss, val_f1 = evaluate(model, val_loader, crit, config.DEVICE,\n",
    "                                    [0.5]*config.NUM_LABELS, config.LABELS,\n",
    "                                    config.USE_FP16, show_report=False)\n",
    "\n",
    "        print(f\"  Train: Loss={tr_loss:.4f}, F1={tr_f1:.4f}\")\n",
    "        print(f\"  Val:   Loss={val_loss:.4f}, F1={val_f1:.4f} (thresh=0.5)\")\n",
    "\n",
    "        # Threshold tuning from epoch 4\n",
    "        if ep >= 3:\n",
    "            thresholds = find_optimal_thresholds(model, val_loader, config.DEVICE,\n",
    "                                                config.LABELS, config.USE_FP16)\n",
    "            _, val_f1_tuned = evaluate(model, val_loader, crit, config.DEVICE, thresholds,\n",
    "                                      config.LABELS, config.USE_FP16,\n",
    "                                      show_report=(ep >= epochs - 2))\n",
    "\n",
    "            print(f\"  Val with tuned thresholds: F1={val_f1_tuned:.4f}\")\n",
    "\n",
    "            if val_f1_tuned > best_f1:\n",
    "                best_f1, best_thresholds, p_cnt = val_f1_tuned, thresholds, 0\n",
    "                # Save with only tensors (convert threshold list to tensor)\n",
    "                torch.save({\n",
    "                    'model': model.state_dict(),\n",
    "                    'thresholds': torch.tensor(thresholds, dtype=torch.float32),\n",
    "                    'f1': torch.tensor(val_f1_tuned, dtype=torch.float32)\n",
    "                }, f\"{config.OUTPUT_DIR}/best_{lang}.pt\")\n",
    "                print(f\"  âœ“ Saved (F1={best_f1:.4f})\")\n",
    "            else:\n",
    "                p_cnt += 1\n",
    "                print(f\"  No improvement ({p_cnt}/{patience})\")\n",
    "\n",
    "        if ep >= 6 and p_cnt >= patience:\n",
    "            print(f\"  Early stopping at epoch {ep+1}\")\n",
    "            break\n",
    "\n",
    "    # Load best (now with weights_only=True support)\n",
    "    ckpt = torch.load(f\"{config.OUTPUT_DIR}/best_{lang}.pt\", weights_only=True)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    best_f1 = float(ckpt['f1'].item())\n",
    "    best_thresholds = ckpt['thresholds'].tolist()\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FINAL: {lang.upper()} F1-Macro={best_f1:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return model, tokenizer, best_f1, best_thresholds\n",
    "\n",
    "def predict_with_mcd(model, ids, mask, n_samples=5):\n",
    "    \"\"\"Multi-sample dropout for uncertainty estimation\"\"\"\n",
    "    model.train()  # Enable dropout\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            logits = model(ids, mask)\n",
    "            probs = torch.sigmoid(logits.float())\n",
    "            predictions.append(probs)\n",
    "\n",
    "    predictions = torch.stack(predictions)\n",
    "    mean_pred = predictions.mean(dim=0)\n",
    "\n",
    "    return mean_pred\n",
    "\n",
    "def predict(model, tokenizer, test_file, out_file, thresholds, label_names, config):\n",
    "    print(f\"\\nPredicting: {test_file}\")\n",
    "\n",
    "    df = pd.read_csv(test_file)\n",
    "    df['text'] = df['text'].apply(TextPreprocessor().clean)\n",
    "\n",
    "    for label in label_names:\n",
    "        df[label] = 0\n",
    "\n",
    "    ds = MultiLabelDataset(df['text'].values, df, tokenizer, config.MAX_LENGTH, label_names)\n",
    "    loader = DataLoader(ds, config.BATCH_SIZE_ENG*2, shuffle=False,\n",
    "                       num_workers=2, pin_memory=True)\n",
    "\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "\n",
    "    print(f\"  Using multi-sample dropout ({config.INFERENCE_SAMPLES} samples)...\")\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"  Predict\", leave=False):\n",
    "        ids = batch['input_ids'].to(config.DEVICE)\n",
    "        mask = batch['attention_mask'].to(config.DEVICE)\n",
    "\n",
    "        mean_probs = predict_with_mcd(model, ids, mask, n_samples=config.INFERENCE_SAMPLES)\n",
    "        all_probs.append(mean_probs.cpu().numpy())\n",
    "\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    # Apply thresholds\n",
    "    predictions = np.zeros_like(all_probs, dtype=int)\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        predictions[:, i] = (all_probs[:, i] >= thresh).astype(int)\n",
    "\n",
    "    out_df = pd.DataFrame({'id': df['id']})\n",
    "    for i, label in enumerate(label_names):\n",
    "        out_df[label] = predictions[:, i]\n",
    "\n",
    "    out_df.to_csv(out_file, index=False)\n",
    "\n",
    "    print(f\"âœ“ Saved: {out_file}\")\n",
    "    print(f\"  Prediction Statistics:\")\n",
    "    for i, label in enumerate(label_names):\n",
    "        count = predictions[:, i].sum()\n",
    "        pct = count / len(predictions) * 100\n",
    "        print(f\"    {label:20s}: {count:5d} ({pct:5.2f}%) [t={thresholds[i]:.3f}]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SemEval Task 9 - Subtask 3: FIXED\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # ENGLISH\n",
    "    print(\"\\nðŸ“Š Loading English data...\")\n",
    "    eng_train = load_data(Config.TRAIN_ENG, Config.LABELS)\n",
    "\n",
    "    eng_model, eng_tok, eng_f1, eng_t = train_model(\n",
    "        eng_train, 'english', Config.MODEL_ENG, Config.LR_ENG,\n",
    "        Config.BATCH_SIZE_ENG, Config.EPOCHS_ENG, Config\n",
    "    )\n",
    "\n",
    "    predict(eng_model, eng_tok, Config.DEV_ENG,\n",
    "           f\"{Config.PREDICTIONS_DIR}/pred_eng.csv\", eng_t, Config.LABELS, Config)\n",
    "\n",
    "    del eng_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # KISWAHILI\n",
    "    print(\"\\nðŸ“Š Loading Kiswahili data...\")\n",
    "    swa_train = load_data(Config.TRAIN_SWA, Config.LABELS)\n",
    "\n",
    "    swa_model, swa_tok, swa_f1, swa_t = train_model(\n",
    "        swa_train, 'kiswahili', Config.MODEL_SWA, Config.LR_SWA,\n",
    "        Config.BATCH_SIZE_SWA, Config.EPOCHS_SWA, Config\n",
    "    )\n",
    "\n",
    "    predict(swa_model, swa_tok, Config.DEV_SWA,\n",
    "           f\"{Config.PREDICTIONS_DIR}/pred_swa.csv\", swa_t, Config.LABELS, Config)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"English:   Val F1={eng_f1:.4f}\")\n",
    "    print(f\"Kiswahili: Val F1={swa_f1:.4f}\")\n",
    "    print(f\"Average:   {(eng_f1+swa_f1)/2:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nðŸ“¦ Creating submission...\")\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('subtask_3.zip', 'w') as zipf:\n",
    "        zipf.write(f\"{Config.PREDICTIONS_DIR}/pred_eng.csv\", 'subtask_3/pred_eng.csv')\n",
    "        zipf.write(f\"{Config.PREDICTIONS_DIR}/pred_swa.csv\", 'subtask_3/pred_swa.csv')\n",
    "    print(\"âœ… DONE! Download subtask_3.zip\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
